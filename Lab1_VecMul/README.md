# Лабораторная работа №1: Сумма элементов вектора
***

## Постановка задачи:

Реализовать алгоритм сложения элементов вектора.

Языки: __C++__, __CUDA__

Входные данные: Вектор размером 1 000 ... 1 000 000 значений.

Выходные данные: сумма элементов вектора + время вычисления.

## Описание работы программы на CUDA:

Алгоритм распараллеливания заключается в том, что каждая нить будет складывать пару элементов массива до тех пор, пока в массиве не останется только один элемент - искомая сумма.

![Схема работы алгоритма]()

Сначала создаётся копия исходного массива в разделяемой памяти:

```
    extern __shared__ float aShared[];
    unsigned int tid = threadIdx.x;
    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
    aShared[tid] = a[i];
    __syncthreads();
```

Далее производим попарное суммирование элементов и синхронизацию нитей:

```
    for(unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {
        if (tid < s) {
            aShared[tid] += aShared[tid + s];
        }
        __syncthreads();
    }
```

В конце  каждый блок записывает свою сумму в результирующий массив:

```
    if (tid == 0) result[blockIdx.x] = aShared[0];
```

Результатом вычисления суммы элементов в векторе будет сумма элементов вектора __result__.

## Описание работы программы на C++:

Для автоматического распсраллеливания программы на C++ был применён API OpenMP. Кроме того, вычисление суммы элементов было написано так, чтобы компилятор смог применить векторизацию:

```
    float result = 0.0f;
    #pragma omp parallel for simd schedule(static) shared(size, a) reduction(+:result) default(none)
    for(int i = 0; i < size; i += 4) {
        result += a[i] + a[i+1] + a[i+2] + a[i+3];
    }
```

Результатом вычисления суммы элементов в векторе будет значение переменной __result__.

## Пример работы программы:

Пример работы программы с количеством элементов вектора 1 000 000:

![Работа программы с количеством элементов вектора 1 000 000]()


## Результаты экспериментов:

| Размер вектора    | 1 000    | 10 000   | 50 000   | 100 000 | 500 000   | 1 000 000 | 
| ----------------- | -------- | -------- | -------- | ------- | --------- | --------- | 
| Время на CPU, с   | 0,00006  | 2        | 2        | 2       | 3         | 4         | 
| Время на GPU, мс  | 0,00512  | 0,043    | 0,045    | 0,049   | 0,051     | 0,057     | 
| Ускорение, раз    | 11,71875 | 46,511   | 44,444   | 40,816  | 58,823    | 70,175    | 

График зависимости времени работы программы на __CPU__ от количества элементов вектора:

![График зависимости времени работы программы на CPU от количества элементов вектора]()

График зависимости времени работы программы на __GPU__ от количества элементов вектора:

![График зависимости времени работы программы на GPU от количества элементов вектора]()

График зависимости __ускорения__ от размера матрицы:

![График зависимости ускорения от размера количества элементов вектора]()

## Выводы:

1. Программа с использованием CUDA (GPU) работает быстрее, чем на CPU;
2. С увеличением количества элементов вектора увеличивается и время работы программы. По графику ускорения видно, что для вектора с количеством элементов от 1000 до 1000000 ускорение GPU-версии составляет от 2 до 11 раз, что показывает, что на этих объемах данных выгоднее использовать распараллеливание и векторизацию на CPU.